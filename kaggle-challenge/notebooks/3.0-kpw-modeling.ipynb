{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load(\"../data/processed/X_train\")\n",
    "y_train = joblib.load(\"../data/processed/y_train\")\n",
    "X_val = joblib.load(\"../data/processed/X_val\")\n",
    "y_val = joblib.load(\"../data/processed/y_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "max_roc_auc_score = 0.0\n",
    "def get_roc_auc_score(model):\n",
    "    global max_roc_auc_score\n",
    "    model.fit(X_train, y_train)\n",
    "    # If it's logistic regression, use predict_proba\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        y_pred_train = model.predict_proba(X_train)[:,-1]\n",
    "        y_pred = model.predict_proba(X_val)[:,-1]\n",
    "        z_pred_train = model.predict(X_train)\n",
    "        z_pred = model.predict(X_val)\n",
    "        print(\"roc_auc_score for training classification: \"+ str(roc_auc_score(y_train, z_pred_train)))\n",
    "        print(\"roc_auc_score for testing classification: \"+ str(roc_auc_score(y_val, z_pred)))\n",
    "    else:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "    if isinstance(model, LinearRegression):\n",
    "        print('Coef_ is :')\n",
    "        print(model.coef_)\n",
    "\n",
    "    sureOne = np.vectorize(lambda x: 1 if x > 1 else x )\n",
    "    sureZero = np.vectorize(lambda x: 0 if x < 0 else x )\n",
    "\n",
    "    y_pred = sureOne(y_pred)\n",
    "    y_pred = sureZero(y_pred)\n",
    "\n",
    "    # # print(y_pred)\n",
    "\n",
    "    val_roc_auc_score = roc_auc_score(y_val, y_pred)\n",
    "    print(\"roc_auc_score for training set: \"+ str(roc_auc_score(y_train, y_pred_train)))\n",
    "    print(\"roc_auc_score for testing set: \"+ str(val_roc_auc_score))\n",
    "\n",
    "    if max_roc_auc_score < val_roc_auc_score:\n",
    "        print(\"The score is better than \"+ str(max_roc_auc_score) + \" so save the model\")\n",
    "        joblib.dump(model, \"../models/kpw_best_model\")\n",
    "        max_roc_auc_score = val_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.5\nroc_auc_score for testing set: 0.5\nThe score is better than 0.0 so save the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "get_roc_auc_score(Lasso(alpha=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training classification: 0.5924046991142659\nroc_auc_score for testing classification: 0.5804145793983193\nroc_auc_score for training set: 0.7028033075103917\nroc_auc_score for testing set: 0.6971727208854581\nThe score is better than 0.5 so save the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "get_roc_auc_score(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training classification: 0.5924046991142659\nroc_auc_score for testing classification: 0.5804145793983193\nroc_auc_score for training set: 0.7028033075103917\nroc_auc_score for testing set: 0.6971727208854581\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(LogisticRegression(l1_ratio=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training classification: 0.5924046991142659\nroc_auc_score for testing classification: 0.5804145793983193\nroc_auc_score for training set: 0.7028033075103917\nroc_auc_score for testing set: 0.6971727208854581\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(LogisticRegression(random_state=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coef_ is :\n[[ 0.82869471 -0.25384755  1.64482246 -1.87596627  0.54290857  0.13775574\n  -0.15544202 -0.62118787  0.42155907  0.41178312 -0.16076054  0.26213857\n  -0.06953298 -0.37159479 -0.1532048   0.37906973  0.47005124 -0.09275599\n   0.24418388  0.11303833  0.09796879 -0.04576895 -0.01287444 -0.00670456\n  -0.04899562  0.0341028 ]]\nroc_auc_score for training set: 0.7022802934929436\nroc_auc_score for testing set: 0.6968841531849663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "get_roc_auc_score(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.8060798418575934\nroc_auc_score for testing set: 0.7533527460695483\nThe score is better than 0.6971727208854581 so save the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "get_roc_auc_score(GradientBoostingRegressor(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.791542006121533\nroc_auc_score for testing set: 0.7458642431542162\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(GradientBoostingRegressor(random_state=8, learning_rate=0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 1.0\nroc_auc_score for testing set: 0.9649048068763516\nThe score is better than 0.7533527460695483 so save the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "get_roc_auc_score(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.9228456976984583\nroc_auc_score for testing set: 0.8325565957679779\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(RandomForestRegressor(n_estimators = 150, random_state = 8, max_depth = 8, min_samples_leaf = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.7768035579520262\nroc_auc_score for testing set: 0.7362981668537223\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 5, min_samples_leaf = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.7775002563244917\nroc_auc_score for testing set: 0.7367161908151069\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 5, min_samples_leaf = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.7055930074118397\nroc_auc_score for testing set: 0.6972890604326918\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 2, min_samples_leaf = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc_score for training set: 0.7406960512581751\nroc_auc_score for testing set: 0.7198771819368025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "r1 = LinearRegression()\n",
    "r2 = LinearRegression()\n",
    "r5 = LinearRegression()\n",
    "r6 = LinearRegression()\n",
    "r7 = Lasso(alpha=0.1)\n",
    "r8 = GradientBoostingRegressor(random_state=0, learning_rate=0.05)\n",
    "r9 = RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 5, min_samples_leaf = 5)\n",
    "r3 = RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 2, min_samples_leaf = 2)\n",
    "# r4 = RandomForestRegressor(n_estimators = 100, random_state = 8, max_depth = 5, min_samples_leaf = 5)\n",
    "r4 = GradientBoostingRegressor(random_state=5)\n",
    "vr = VotingRegressor([('lr', r1), ('lr2', r2), ('rf', r3), ('rfh', r4), ('lr3', r5), ('lr4', r6), ('lr5', r7), ('lr6', r8), ('lr7', r9)])\n",
    "# vr = VotingRegressor([('lr', r1), ('lr2', r2), ('rf', r3), ('rfh', r4), ('lr5', r7), ('lr6', r8), ('lr7', r9)])\n",
    "get_roc_auc_score(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vr = VotingRegressor([('lr', r1), ('lr2', r2), ('rf', r3), ('rfh', r4), ('lr5', r7), ('lr6', r8), ('lr7', r9)])\n",
    "# get_roc_auc_score(vr)"
   ]
  }
 ]
}